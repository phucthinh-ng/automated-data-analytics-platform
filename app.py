"""
Automated Data Analytics Web Application
=========================================
·ª®ng d·ª•ng ph√¢n t√≠ch d·ªØ li·ªáu t·ª± ƒë·ªông v·ªõi Streamlit
Author: Data Analyst Portfolio Project
"""

import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
import seaborn as sns
import matplotlib.pyplot as plt
from io import StringIO
import warnings
warnings.filterwarnings('ignore')

# ==================== PAGE CONFIGURATION ====================
st.set_page_config(
    page_title="Automated Data Analytics",
    page_icon="üìä",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ==================== CUSTOM CSS ====================
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        font-weight: bold;
        color: #1f77b4;
        text-align: center;
        padding: 1rem 0;
    }
    .sub-header {
        font-size: 1.2rem;
        color: #666;
        text-align: center;
        margin-bottom: 2rem;
    }
    .metric-card {
        background-color: #f0f2f6;
        padding: 1rem;
        border-radius: 0.5rem;
        border-left: 4px solid #1f77b4;
    }
    .stTabs [data-baseweb="tab-list"] {
        gap: 2rem;
    }
    .stTabs [data-baseweb="tab"] {
        font-size: 1.1rem;
        font-weight: 600;
    }
</style>
""", unsafe_allow_html=True)

# ==================== UTILITY FUNCTIONS ====================

@st.cache_data
def load_data(file):
    """
    Load CSV or Excel file with error handling
    
    Args:
        file: Uploaded file object from Streamlit
    
    Returns:
        pd.DataFrame: Loaded dataframe or None if error
    """
    try:
        if file.name.endswith('.csv'):
            # Try different encodings
            try:
                df = pd.read_csv(file, encoding='utf-8')
            except UnicodeDecodeError:
                df = pd.read_csv(file, encoding='latin-1')
        elif file.name.endswith(('.xlsx', '.xls')):
            df = pd.read_excel(file)
        else:
            st.error("‚ùå ƒê·ªãnh d·∫°ng file kh√¥ng ƒë∆∞·ª£c h·ªó tr·ª£. Vui l√≤ng upload file CSV ho·∫∑c Excel.")
            return None
        
        return df
    except Exception as e:
        st.error(f"‚ùå L·ªói khi ƒë·ªçc file: {str(e)}")
        return None


def analyze_column_types(df):
    """
    Ph√¢n t√≠ch v√† ph√¢n lo·∫°i c√°c c·ªôt trong dataframe
    
    Returns:
        dict: Dictionary ch·ª©a c√°c lo·∫°i c·ªôt kh√°c nhau
    """
    numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns.tolist()
    categorical_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()
    datetime_cols = df.select_dtypes(include=['datetime64']).columns.tolist()
    
    return {
        'numeric': numeric_cols,
        'categorical': categorical_cols,
        'datetime': datetime_cols
    }


def clean_data(df, remove_duplicates=True, handle_missing='drop', convert_types=True):
    """
    Smart data cleaning function with enhanced categorical support
    
    Args:
        df: Input dataframe
        remove_duplicates: C√≥ x√≥a d·ªØ li·ªáu tr√πng l·∫∑p kh√¥ng
        handle_missing: C√°ch x·ª≠ l√Ω missing values ('drop', 'fill_mean', 'fill_median', 'fill_mode')
        convert_types: T·ª± ƒë·ªông chuy·ªÉn ƒë·ªïi ki·ªÉu d·ªØ li·ªáu
    
    Returns:
        pd.DataFrame: Cleaned dataframe
        dict: Cleaning statistics with warnings
    """
    df_cleaned = df.copy()
    stats = {
        'original_rows': len(df),
        'original_cols': len(df.columns),
        'duplicates_removed': 0,
        'missing_handled': 0,
        'types_converted': 0,
        'warnings': []
    }
    
    # 1. Remove duplicates
    if remove_duplicates:
        before = len(df_cleaned)
        df_cleaned = df_cleaned.drop_duplicates()
        stats['duplicates_removed'] = before - len(df_cleaned)
    
    # 2. Handle missing values
    if handle_missing == 'drop':
        before = len(df_cleaned)
        df_cleaned = df_cleaned.dropna()
        stats['missing_handled'] = before - len(df_cleaned)
    
    elif handle_missing == 'fill_mean':
        # Only apply to numeric columns
        numeric_cols = df_cleaned.select_dtypes(include=['int64', 'float64']).columns
        categorical_cols_with_nulls = df_cleaned.select_dtypes(include=['object', 'category']).columns[
            df_cleaned.select_dtypes(include=['object', 'category']).isnull().any()
        ].tolist()
        
        for col in numeric_cols:
            if df_cleaned[col].isnull().any():
                df_cleaned[col].fillna(df_cleaned[col].mean(), inplace=True)
                stats['missing_handled'] += 1
        
        # Warning for categorical columns
        if categorical_cols_with_nulls:
            stats['warnings'].append(
                f"‚ö†Ô∏è Ph∆∞∆°ng ph√°p 'Mean' kh√¥ng √°p d·ª•ng cho c·ªôt d·∫°ng ch·ªØ: {', '.join(categorical_cols_with_nulls)}. "
                f"C√°c c·ªôt n√†y v·∫´n c√≤n gi√° tr·ªã thi·∫øu."
            )
    
    elif handle_missing == 'fill_median':
        # Only apply to numeric columns
        numeric_cols = df_cleaned.select_dtypes(include=['int64', 'float64']).columns
        categorical_cols_with_nulls = df_cleaned.select_dtypes(include=['object', 'category']).columns[
            df_cleaned.select_dtypes(include=['object', 'category']).isnull().any()
        ].tolist()
        
        for col in numeric_cols:
            if df_cleaned[col].isnull().any():
                df_cleaned[col].fillna(df_cleaned[col].median(), inplace=True)
                stats['missing_handled'] += 1
        
        # Warning for categorical columns
        if categorical_cols_with_nulls:
            stats['warnings'].append(
                f"‚ö†Ô∏è Ph∆∞∆°ng ph√°p 'Median' kh√¥ng √°p d·ª•ng cho c·ªôt d·∫°ng ch·ªØ: {', '.join(categorical_cols_with_nulls)}. "
                f"C√°c c·ªôt n√†y v·∫´n c√≤n gi√° tr·ªã thi·∫øu."
            )
    
    elif handle_missing == 'fill_mode':
        # Apply to ALL columns (both numeric and categorical)
        numeric_filled = 0
        categorical_filled = 0
        
        for col in df_cleaned.columns:
            if df_cleaned[col].isnull().any():
                mode_val = df_cleaned[col].mode()
                if not mode_val.empty:
                    df_cleaned[col].fillna(mode_val[0], inplace=True)
                    stats['missing_handled'] += 1
                    
                    # Track what type of column was filled
                    if df_cleaned[col].dtype in ['int64', 'float64']:
                        numeric_filled += 1
                    else:
                        categorical_filled += 1
        
        if categorical_filled > 0:
            stats['warnings'].append(
                f"‚ÑπÔ∏è ƒê√£ ƒëi·ªÅn {categorical_filled} c·ªôt d·∫°ng ch·ªØ v√† {numeric_filled} c·ªôt s·ªë b·∫±ng gi√° tr·ªã ph·ªï bi·∫øn nh·∫•t (Mode)."
            )
    
    # 3. Auto convert data types (detect numeric columns stored as strings)
    if convert_types:
        for col in df_cleaned.select_dtypes(include=['object']).columns:
            # Try to convert to numeric
            try:
                converted = pd.to_numeric(df_cleaned[col], errors='coerce')
                # If more than 80% can be converted, it's probably numeric
                if converted.notna().sum() / len(df_cleaned) > 0.8:
                    df_cleaned[col] = converted
                    stats['types_converted'] += 1
            except:
                pass
    
    stats['final_rows'] = len(df_cleaned)
    stats['final_cols'] = len(df_cleaned.columns)
    
    return df_cleaned, stats


def detect_outliers(df, column, method='iqr'):
    """
    Detect outliers using IQR method
    
    Args:
        df: Input dataframe
        column: Column name to check for outliers
        method: Detection method (currently supports 'iqr')
    
    Returns:
        pd.DataFrame: Dataframe with outlier information
        dict: Outlier statistics
    """
    if column not in df.columns or df[column].dtype not in ['int64', 'float64']:
        return None, None
    
    data = df[column].dropna()
    
    if method == 'iqr':
        Q1 = data.quantile(0.25)
        Q3 = data.quantile(0.75)
        IQR = Q3 - Q1
        lower_bound = Q1 - 1.5 * IQR
        upper_bound = Q3 + 1.5 * IQR
        
        outliers_mask = (df[column] < lower_bound) | (df[column] > upper_bound)
        outliers_df = df[outliers_mask].copy()
        outliers_df['outlier_reason'] = outliers_df[column].apply(
            lambda x: f"Below {lower_bound:.2f}" if x < lower_bound else f"Above {upper_bound:.2f}"
        )
        
        stats = {
            'total_values': len(data),
            'outliers_count': len(outliers_df),
            'outliers_percentage': (len(outliers_df) / len(data)) * 100,
            'lower_bound': lower_bound,
            'upper_bound': upper_bound,
            'Q1': Q1,
            'Q3': Q3,
            'IQR': IQR
        }
        
        return outliers_df, stats
    
    return None, None


def suggest_chart_type(x_col, y_col, df):
    """
    G·ª£i √Ω lo·∫°i bi·ªÉu ƒë·ªì ph√π h·ª£p d·ª±a tr√™n ki·ªÉu d·ªØ li·ªáu
    
    Returns:
        str: Lo·∫°i bi·ªÉu ƒë·ªì ƒë∆∞·ª£c g·ª£i √Ω
    """
    col_types = analyze_column_types(df)
    
    x_is_numeric = x_col in col_types['numeric']
    y_is_numeric = y_col in col_types['numeric'] if y_col else False
    
    if y_col is None:
        # Single column analysis
        if x_is_numeric:
            return 'histogram'
        else:
            return 'bar'
    else:
        # Two column analysis
        if x_is_numeric and y_is_numeric:
            return 'scatter'
        elif not x_is_numeric and y_is_numeric:
            return 'box'
        elif x_is_numeric and not y_is_numeric:
            return 'box'
        else:
            return 'bar'


def create_visualization(df, chart_type, x_col, y_col=None, color_col=None):
    """
    T·∫°o bi·ªÉu ƒë·ªì t∆∞∆°ng t√°c v·ªõi Plotly
    
    Returns:
        plotly.graph_objects.Figure: Interactive chart
    """
    try:
        if chart_type == 'scatter':
            fig = px.scatter(df, x=x_col, y=y_col, color=color_col,
                           title=f"{y_col} vs {x_col}",
                           template='plotly_white',
                           hover_data=df.columns)
        elif chart_type == 'bar':
            if y_col:
                fig = px.bar(df, x=x_col, y=y_col, color=color_col,
                           title=f"{y_col} by {x_col}",
                           template='plotly_white')
            else:
                value_counts = df[x_col].value_counts().reset_index()
                value_counts.columns = [x_col, 'count']
                fig = px.bar(value_counts, x=x_col, y='count',
                           title=f"Distribution of {x_col}",
                           template='plotly_white')
        elif chart_type == 'box':
            fig = px.box(df, x=x_col, y=y_col, color=color_col,
                        title=f"{y_col} Distribution by {x_col}",
                        template='plotly_white')
        elif chart_type == 'histogram':
            fig = px.histogram(df, x=x_col, color=color_col,
                             title=f"Distribution of {x_col}",
                             template='plotly_white')
        elif chart_type == 'line':
            fig = px.line(df, x=x_col, y=y_col, color=color_col,
                         title=f"{y_col} over {x_col}",
                         template='plotly_white')
        else:
            return None
        
        fig.update_layout(
            height=500,
            hovermode='closest',
            showlegend=True
        )
        
        return fig
    except Exception as e:
        st.error(f"‚ùå L·ªói khi t·∫°o bi·ªÉu ƒë·ªì: {str(e)}")
        return None


def create_correlation_heatmap(df):
    """
    T·∫°o correlation heatmap cho c√°c c·ªôt numeric
    
    Returns:
        plotly.graph_objects.Figure: Heatmap
    """
    numeric_df = df.select_dtypes(include=['int64', 'float64'])
    
    if len(numeric_df.columns) < 2:
        return None
    
    corr_matrix = numeric_df.corr()
    
    fig = px.imshow(corr_matrix,
                    text_auto='.2f',
                    aspect='auto',
                    color_continuous_scale='RdBu_r',
                    title='Ma tr·∫≠n t∆∞∆°ng quan (Correlation Matrix)',
                    labels=dict(color="Correlation"))
    
    fig.update_layout(height=600)
    
    return fig


def convert_df_to_csv(df):
    """
    Convert dataframe to CSV for download
    """
    return df.to_csv(index=False).encode('utf-8')


# ==================== MAIN APPLICATION ====================

def main():
    # Header
    st.markdown('<div class="main-header">üìä Automated Data Analytics Platform</div>', unsafe_allow_html=True)
    st.markdown('<div class="sub-header">Ph√¢n t√≠ch d·ªØ li·ªáu t·ª± ƒë·ªông v·ªõi AI-powered insights</div>', unsafe_allow_html=True)
    
    # ==================== SIDEBAR ====================
    with st.sidebar:
        st.header("‚öôÔ∏è C·∫•u h√¨nh")
        
        # File upload
        st.subheader("üìÅ Upload D·ªØ li·ªáu")
        uploaded_file = st.file_uploader(
            "Ch·ªçn file CSV ho·∫∑c Excel",
            type=['csv', 'xlsx', 'xls'],
            help="H·ªó tr·ª£ ƒë·ªãnh d·∫°ng: CSV, Excel (.xlsx, .xls)"
        )
        
        # Initialize session state
        if 'df_original' not in st.session_state:
            st.session_state.df_original = None
        if 'df_cleaned' not in st.session_state:
            st.session_state.df_cleaned = None
        if 'cleaning_stats' not in st.session_state:
            st.session_state.cleaning_stats = None
        if 'last_uploaded_file' not in st.session_state:
            st.session_state.last_uploaded_file = None
        
        # Load data and auto-reset on new file
        if uploaded_file is not None:
            # Check if this is a new file
            current_file_name = uploaded_file.name
            
            if st.session_state.last_uploaded_file != current_file_name:
                # New file detected - reset cleaned data
                st.session_state.df_cleaned = None
                st.session_state.cleaning_stats = None
                st.session_state.last_uploaded_file = current_file_name
                
                # Load the new file
                df = load_data(uploaded_file)
                if df is not None:
                    st.session_state.df_original = df
                    st.success(f"‚úÖ ƒê√£ t·∫£i {len(df)} d√≤ng, {len(df.columns)} c·ªôt")
            elif st.session_state.df_original is None:
                # First time loading
                df = load_data(uploaded_file)
                if df is not None:
                    st.session_state.df_original = df
                    st.success(f"‚úÖ ƒê√£ t·∫£i {len(df)} d√≤ng, {len(df.columns)} c·ªôt")
        
        # Data cleaning options (only show if data is loaded)
        if st.session_state.df_original is not None:
            st.divider()
            st.subheader("üßπ T√πy ch·ªçn l√†m s·∫°ch")
            
            remove_dupes = st.checkbox("X√≥a d·ªØ li·ªáu tr√πng l·∫∑p", value=True)
            
            missing_method = st.selectbox(
                "X·ª≠ l√Ω gi√° tr·ªã thi·∫øu",
                options=['drop', 'fill_mean', 'fill_median', 'fill_mode'],
                format_func=lambda x: {
                    'drop': 'X√≥a d√≤ng c√≥ gi√° tr·ªã thi·∫øu',
                    'fill_mean': 'ƒêi·ªÅn gi√° tr·ªã trung b√¨nh (ch·ªâ s·ªë)',
                    'fill_median': 'ƒêi·ªÅn gi√° tr·ªã trung v·ªã (ch·ªâ s·ªë)',
                    'fill_mode': 'ƒêi·ªÅn gi√° tr·ªã ph·ªï bi·∫øn nh·∫•t (s·ªë & ch·ªØ)'
                }[x]
            )
            
            auto_convert = st.checkbox("T·ª± ƒë·ªông chuy·ªÉn ƒë·ªïi ki·ªÉu d·ªØ li·ªáu", value=True)
            
            st.divider()
            col1, col2 = st.columns(2)
            with col1:
                clean_btn = st.button("üöÄ Clean", type="primary", use_container_width=True)
            with col2:
                reset_btn = st.button("üîÑ Reset", type="secondary", use_container_width=True)
            
            if clean_btn:
                with st.spinner("ƒêang x·ª≠ l√Ω..."):
                    df_cleaned, stats = clean_data(
                        st.session_state.df_original,
                        remove_duplicates=remove_dupes,
                        handle_missing=missing_method,
                        convert_types=auto_convert
                    )
                    st.session_state.df_cleaned = df_cleaned
                    st.session_state.cleaning_stats = stats
                    st.success("‚úÖ Ho√†n th√†nh!")
                    
                    # Show warnings if any
                    if stats.get('warnings'):
                        for warning in stats['warnings']:
                            st.warning(warning)
            
            if reset_btn:
                st.session_state.df_cleaned = None
                st.session_state.cleaning_stats = None
                st.success("‚úÖ ƒê√£ reset v·ªÅ d·ªØ li·ªáu g·ªëc!")
                st.rerun()
    
    # ==================== MAIN CONTENT ====================
    if st.session_state.df_original is None:
        # Welcome screen
        st.info("üëà Vui l√≤ng upload file d·ªØ li·ªáu t·ª´ sidebar ƒë·ªÉ b·∫Øt ƒë·∫ßu ph√¢n t√≠ch")
        
        st.markdown("### ‚ú® T√≠nh nƒÉng n·ªïi b·∫≠t")
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.markdown("""
            **üßπ Smart Cleaning**
            - T·ª± ƒë·ªông ph√°t hi·ªán missing values
            - Lo·∫°i b·ªè d·ªØ li·ªáu tr√πng l·∫∑p
            - Chuy·ªÉn ƒë·ªïi ki·ªÉu d·ªØ li·ªáu th√¥ng minh
            """)
        
        with col2:
            st.markdown("""
            **üìä Interactive Charts**
            - Bi·ªÉu ƒë·ªì t∆∞∆°ng t√°c v·ªõi Plotly
            - G·ª£i √Ω bi·ªÉu ƒë·ªì t·ª± ƒë·ªông
            - Ma tr·∫≠n t∆∞∆°ng quan
            """)
        
        with col3:
            st.markdown("""
            **üéØ Advanced Analytics**
            - Ph√°t hi·ªán outliers (IQR)
            - Th·ªëng k√™ m√¥ t·∫£ chi ti·∫øt
            - Xu·∫•t d·ªØ li·ªáu ƒë√£ l√†m s·∫°ch
            """)
        
        return
    
    # Get working dataframe
    df_work = st.session_state.df_cleaned if st.session_state.df_cleaned is not None else st.session_state.df_original
    
    # Create tabs
    tab1, tab2, tab3, tab4 = st.tabs([
        "üìã T·ªïng quan d·ªØ li·ªáu",
        "üßπ L√†m s·∫°ch d·ªØ li·ªáu", 
        "üìä Ph√¢n t√≠ch tr·ª±c quan",
        "üéØ Th·ªëng k√™ n√¢ng cao"
    ])
    
    # ==================== TAB 1: DATA OVERVIEW ====================
    with tab1:
        st.header("üìã T·ªïng quan d·ªØ li·ªáu")
        
        # Basic metrics
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("S·ªë d√≤ng", f"{len(df_work):,}")
        with col2:
            st.metric("S·ªë c·ªôt", len(df_work.columns))
        with col3:
            st.metric("Gi√° tr·ªã thi·∫øu", f"{df_work.isnull().sum().sum():,}")
        with col4:
            memory_mb = df_work.memory_usage(deep=True).sum() / 1024**2
            st.metric("B·ªô nh·ªõ", f"{memory_mb:.2f} MB")
        
        st.divider()
        
        # Column types
        col_types = analyze_column_types(df_work)
        
        col1, col2 = st.columns(2)
        with col1:
            st.subheader("üìä Ph√¢n lo·∫°i c·ªôt")
            st.write(f"**Numeric:** {len(col_types['numeric'])} c·ªôt")
            st.write(f"**Categorical:** {len(col_types['categorical'])} c·ªôt")
            st.write(f"**Datetime:** {len(col_types['datetime'])} c·ªôt")
        
        with col2:
            st.subheader("üîç Th√¥ng tin chi ti·∫øt")
            buffer = StringIO()
            df_work.info(buf=buffer)
            st.text(buffer.getvalue())
        
        st.divider()
        
        # Data preview
        st.subheader("üëÄ Xem tr∆∞·ªõc d·ªØ li·ªáu")
        st.dataframe(df_work.head(20), use_container_width=True)
        
        # Basic statistics
        st.subheader("üìà Th·ªëng k√™ m√¥ t·∫£")
        st.dataframe(df_work.describe(), use_container_width=True)
    
    # ==================== TAB 2: DATA CLEANING ====================
    with tab2:
        st.header("üßπ L√†m s·∫°ch d·ªØ li·ªáu")
        
        if st.session_state.df_cleaned is not None:
            # Show cleaning statistics
            stats = st.session_state.cleaning_stats
            
            st.success("‚úÖ D·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c l√†m s·∫°ch!")
            
            # Display warnings if any
            if stats.get('warnings'):
                for warning in stats['warnings']:
                    if "‚ö†Ô∏è" in warning:
                        st.warning(warning)
                    else:
                        st.info(warning)
            
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("D√≤ng b·ªã x√≥a", f"{stats['original_rows'] - stats['final_rows']:,}")
            with col2:
                st.metric("D·ªØ li·ªáu tr√πng l·∫∑p", stats['duplicates_removed'])
            with col3:
                st.metric("C·ªôt ƒë∆∞·ª£c chuy·ªÉn ƒë·ªïi", stats['types_converted'])
            
            st.divider()
            
            # Before/After comparison
            col1, col2 = st.columns(2)
            
            with col1:
                st.subheader("üìä Tr∆∞·ªõc khi l√†m s·∫°ch")
                st.write(f"D√≤ng: {stats['original_rows']:,}")
                st.write(f"C·ªôt: {stats['original_cols']}")
                st.write(f"Missing values: {st.session_state.df_original.isnull().sum().sum():,}")
                
                with st.expander("Xem chi ti·∫øt missing values"):
                    missing_df = pd.DataFrame({
                        'Column': st.session_state.df_original.columns,
                        'Missing Count': st.session_state.df_original.isnull().sum().values,
                        'Missing %': (st.session_state.df_original.isnull().sum().values / len(st.session_state.df_original) * 100).round(2)
                    })
                    missing_df = missing_df[missing_df['Missing Count'] > 0].sort_values('Missing Count', ascending=False)
                    st.dataframe(missing_df, use_container_width=True)
            
            with col2:
                st.subheader("‚ú® Sau khi l√†m s·∫°ch")
                st.write(f"D√≤ng: {stats['final_rows']:,}")
                st.write(f"C·ªôt: {stats['final_cols']}")
                st.write(f"Missing values: {st.session_state.df_cleaned.isnull().sum().sum():,}")
                
                if st.session_state.df_cleaned.isnull().sum().sum() > 0:
                    with st.expander("Xem chi ti·∫øt missing values"):
                        missing_df = pd.DataFrame({
                            'Column': st.session_state.df_cleaned.columns,
                            'Missing Count': st.session_state.df_cleaned.isnull().sum().values,
                            'Missing %': (st.session_state.df_cleaned.isnull().sum().values / len(st.session_state.df_cleaned) * 100).round(2)
                        })
                        missing_df = missing_df[missing_df['Missing Count'] > 0].sort_values('Missing Count', ascending=False)
                        st.dataframe(missing_df, use_container_width=True)
        else:
            st.info("üëà S·ª≠ d·ª•ng sidebar ƒë·ªÉ c·∫•u h√¨nh v√† th·ª±c hi·ªán l√†m s·∫°ch d·ªØ li·ªáu")
            
            # Show current data quality issues
            st.subheader("‚ö†Ô∏è C√°c v·∫•n ƒë·ªÅ ch·∫•t l∆∞·ª£ng d·ªØ li·ªáu hi·ªán t·∫°i")
            
            col1, col2 = st.columns(2)
            with col1:
                duplicates = st.session_state.df_original.duplicated().sum()
                st.metric("D√≤ng tr√πng l·∫∑p", duplicates)
            
            with col2:
                missing = st.session_state.df_original.isnull().sum().sum()
                st.metric("Gi√° tr·ªã thi·∫øu", missing)
            
            # Missing values detail
            if missing > 0:
                st.subheader("üìä Chi ti·∫øt gi√° tr·ªã thi·∫øu")
                missing_df = pd.DataFrame({
                    'Column': st.session_state.df_original.columns,
                    'Missing Count': st.session_state.df_original.isnull().sum().values,
                    'Missing %': (st.session_state.df_original.isnull().sum().values / len(st.session_state.df_original) * 100).round(2)
                })
                missing_df = missing_df[missing_df['Missing Count'] > 0].sort_values('Missing Count', ascending=False)
                
                fig = px.bar(missing_df, x='Column', y='Missing %',
                           title='Ph·∫ßn trƒÉm gi√° tr·ªã thi·∫øu theo c·ªôt',
                           template='plotly_white')
                st.plotly_chart(fig, use_container_width=True)
    
    # ==================== TAB 3: VISUALIZATION ====================
    with tab3:
        st.header("üìä Ph√¢n t√≠ch tr·ª±c quan")
        
        col_types = analyze_column_types(df_work)
        
        # Chart builder
        st.subheader("üé® T·∫°o bi·ªÉu ƒë·ªì t∆∞∆°ng t√°c")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            chart_type = st.selectbox(
                "Lo·∫°i bi·ªÉu ƒë·ªì",
                options=['scatter', 'bar', 'box', 'histogram', 'line'],
                format_func=lambda x: {
                    'scatter': 'Scatter Plot',
                    'bar': 'Bar Chart',
                    'box': 'Box Plot',
                    'histogram': 'Histogram',
                    'line': 'Line Chart'
                }[x]
            )
        
        with col2:
            x_col = st.selectbox("Tr·ª•c X", options=df_work.columns)
        
        with col3:
            if chart_type != 'histogram':
                y_col = st.selectbox("Tr·ª•c Y (optional)", options=[None] + list(df_work.columns))
            else:
                y_col = None
        
        # Color option
        color_col = st.selectbox("M√†u theo c·ªôt (optional)", options=[None] + col_types['categorical'])
        
        # Suggest chart type
        if x_col:
            suggested = suggest_chart_type(x_col, y_col, df_work)
            st.info(f"üí° G·ª£i √Ω: V·ªõi s·ª± k·∫øt h·ª£p c·ªôt n√†y, bi·ªÉu ƒë·ªì **{suggested}** c√≥ th·ªÉ ph√π h·ª£p nh·∫•t")
        
        # Create chart
        if st.button("üé® T·∫°o bi·ªÉu ƒë·ªì", type="primary"):
            fig = create_visualization(df_work, chart_type, x_col, y_col, color_col)
            if fig:
                st.plotly_chart(fig, use_container_width=True)
        
        st.divider()
        
        # Correlation heatmap
        if len(col_types['numeric']) >= 2:
            st.subheader("üî• Ma tr·∫≠n t∆∞∆°ng quan")
            
            if st.checkbox("Hi·ªÉn th·ªã Heatmap", value=False):
                fig = create_correlation_heatmap(df_work)
                if fig:
                    st.plotly_chart(fig, use_container_width=True)
                    
                    # Show top correlations
                    numeric_df = df_work[col_types['numeric']]
                    corr_matrix = numeric_df.corr()
                    
                    # Get top positive correlations
                    corr_pairs = []
                    for i in range(len(corr_matrix.columns)):
                        for j in range(i+1, len(corr_matrix.columns)):
                            corr_pairs.append({
                                'Column 1': corr_matrix.columns[i],
                                'Column 2': corr_matrix.columns[j],
                                'Correlation': corr_matrix.iloc[i, j]
                            })
                    
                    corr_df = pd.DataFrame(corr_pairs).sort_values('Correlation', ascending=False, key=abs)
                    
                    col1, col2 = st.columns(2)
                    with col1:
                        st.write("**Top 5 t∆∞∆°ng quan d∆∞∆°ng:**")
                        st.dataframe(corr_df.head(5), use_container_width=True)
                    
                    with col2:
                        st.write("**Top 5 t∆∞∆°ng quan √¢m:**")
                        st.dataframe(corr_df.tail(5), use_container_width=True)
    
    # ==================== TAB 4: ADVANCED STATISTICS ====================
    with tab4:
        st.header("üéØ Th·ªëng k√™ n√¢ng cao")
        
        # Outlier detection
        st.subheader("üîç Ph√°t hi·ªán Outliers (Ph∆∞∆°ng ph√°p IQR)")
        
        numeric_cols = col_types['numeric']
        
        if len(numeric_cols) > 0:
            selected_col = st.selectbox("Ch·ªçn c·ªôt ƒë·ªÉ ph√¢n t√≠ch outliers", options=numeric_cols)
            
            if st.button("üîé Ph√°t hi·ªán Outliers", type="primary"):
                outliers_df, stats = detect_outliers(df_work, selected_col)
                
                if outliers_df is not None and stats is not None:
                    col1, col2, col3 = st.columns(3)
                    
                    with col1:
                        st.metric("T·ªïng s·ªë gi√° tr·ªã", f"{stats['total_values']:,}")
                    with col2:
                        st.metric("S·ªë Outliers", f"{stats['outliers_count']:,}")
                    with col3:
                        st.metric("Ph·∫ßn trƒÉm", f"{stats['outliers_percentage']:.2f}%")
                    
                    st.divider()
                    
                    # Show IQR statistics
                    col1, col2 = st.columns(2)
                    with col1:
                        st.write("**üìä Th·ªëng k√™ IQR:**")
                        st.write(f"Q1 (25%): {stats['Q1']:.2f}")
                        st.write(f"Q3 (75%): {stats['Q3']:.2f}")
                        st.write(f"IQR: {stats['IQR']:.2f}")
                    
                    with col2:
                        st.write("**üìè Ng∆∞·ª°ng Outlier:**")
                        st.write(f"Lower Bound: {stats['lower_bound']:.2f}")
                        st.write(f"Upper Bound: {stats['upper_bound']:.2f}")
                    
                    # Boxplot
                    fig = px.box(df_work, y=selected_col,
                               title=f"Box Plot - {selected_col}",
                               template='plotly_white')
                    st.plotly_chart(fig, use_container_width=True)
                    
                    # Show outliers table
                    if len(outliers_df) > 0:
                        st.subheader("‚ö†Ô∏è Danh s√°ch Outliers")
                        st.dataframe(outliers_df, use_container_width=True)
                    else:
                        st.success("‚úÖ Kh√¥ng ph√°t hi·ªán outliers trong c·ªôt n√†y!")
        else:
            st.warning("‚ö†Ô∏è Kh√¥ng c√≥ c·ªôt numeric ƒë·ªÉ ph√¢n t√≠ch outliers")
        
        st.divider()
        
        # Export data
        st.subheader("üíæ Xu·∫•t d·ªØ li·ªáu")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.write("**Xu·∫•t d·ªØ li·ªáu g·ªëc:**")
            csv_original = convert_df_to_csv(st.session_state.df_original)
            st.download_button(
                label="üì• Download Original Data (CSV)",
                data=csv_original,
                file_name='original_data.csv',
                mime='text/csv'
            )
        
        with col2:
            if st.session_state.df_cleaned is not None:
                st.write("**Xu·∫•t d·ªØ li·ªáu ƒë√£ l√†m s·∫°ch:**")
                csv_cleaned = convert_df_to_csv(st.session_state.df_cleaned)
                st.download_button(
                    label="üì• Download Cleaned Data (CSV)",
                    data=csv_cleaned,
                    file_name='cleaned_data.csv',
                    mime='text/csv'
                )
            else:
                st.info("Ch∆∞a c√≥ d·ªØ li·ªáu ƒë√£ l√†m s·∫°ch")


# ==================== RUN APPLICATION ====================
if __name__ == "__main__":
    main()
